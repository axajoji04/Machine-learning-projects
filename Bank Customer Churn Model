import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.under_sampling import RandomUnderSampler
from imblearn.over_sampling import RandomOverSampler
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.model_selection import GridSearchCV

# Load the dataset
df = pd.read_csv('https://github.com/YBIFoundation/Dataset/raw/main/Bank%20Churn%20Modelling.csv')

# Display the first few rows of the DataFrame
print(df.head())

# Get information about the DataFrame
print(df.info())

# Check for duplicated rows
print("Number of duplicated rows:", df.duplicated().sum())

# Set 'CustomerId' as the index
df.set_index('CustomerId', inplace=True)

# Replace categorical variables with numerical values
df.replace({'Geography': {'France': 2, 'Germany': 1, 'Spain': 0}, 'Gender': {'Male': 0, 'Female': 1},
            'Number of Products': {1: 0, 2: 1, 3: 1, 4: 1}}, inplace=True)

# Create a new feature based on the 'Balance'
df['Zero Balance'] = np.where(df['Balance'] > 0, 1, 0)

# Plot the distribution of the new feature
plt.hist(df['Zero Balance'])
plt.show()

# Count the number of churned customers by geography
print(df.groupby(['Churn', 'Geography']).count())

# Drop unnecessary columns
x = df.drop(['Surname', 'Churn'], axis=1)
y = df['Churn']

# Understanding the class distribution
print("Class distribution:")
print(y.value_counts())
sns.countplot(x='Churn', data=df)
plt.show()

# Random under-sampling
rus = RandomUnderSampler(random_state=2529)
x_rus, y_rus = rus.fit_resample(x, y)
print("Shape after random under-sampling:", x_rus.shape, y_rus.shape)

# Random over-sampling
ros = RandomOverSampler(random_state=2529)
x_ros, y_ros = ros.fit_resample(x, y)
print("Shape after random over-sampling:", x_ros.shape, y_ros.shape)

# Train-test split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=25)
x_train_rus, x_test_rus, y_train_rus, y_test_rus = train_test_split(x_rus, y_rus, test_size=0.3)
x_train_ros, x_test_ros, y_train_ros, y_test_ros = train_test_split(x_ros, y_ros, test_size=0.3)

# Standardize features
sc = StandardScaler()
x_train_scaled = sc.fit_transform(x_train)
x_test_scaled = sc.transform(x_test)

# Print shapes of data splits
print("Shapes of data splits:")
print("Original data:", x_train.shape, x_test.shape, y_train.shape, y_test.shape)
print("Under-sampled data:", x_train_rus.shape, x_test_rus.shape, y_train_rus.shape, y_test_rus.shape)
print("Over-sampled data:", x_train_ros.shape, x_test_ros.shape, y_train_ros.shape, y_test_ros.shape)

# Standarize original data
x_train[['CreditScore', 'Age', 'Tenure', 'Balance', 'Estimated Salary']] = sc.fit_transform(
    x_train[['CreditScore', 'Age', 'Tenure', 'Balance', 'Estimated Salary']])
x_test[['CreditScore', 'Age', 'Tenure', 'Balance', 'Estimated Salary']] = sc.fit_transform(
    x_train[['CreditScore', 'Age', 'Tenure', 'Balance', 'Estimated Salary']])
# Standardize random undersample data
x_train_rus[['CreditScore', 'Age', 'Tenure', 'Balance', 'Estimated Salary']] = sc.fit_transform(
    x_train[['CreditScore', 'Age', 'Tenure', 'Balance', 'Estimated Salary']])
x_test_rus[['CreditScore', 'Age', 'Tenure', 'Balance', 'Estimated Salary']] = sc.fit_transform(
    x_train[['CreditScore', 'Age', 'Tenure', 'Balance', 'Estimated Salary']])
# Standardize random oversample data
x_train_ros[['CreditScore', 'Age', 'Tenure', 'Balance', 'Estimated Salary']] = sc.fit_transform(
    x_train[['CreditScore', 'Age', 'Tenure', 'Balance', 'Estimated Salary']])
x_test_ros[['CreditScore', 'Age', 'Tenure', 'Balance', 'Estimated Salary']] = sc.fit_transform(
    x_train[['CreditScore', 'Age', 'Tenure', 'Balance', 'Estimated Salary']])

# Support vector machine classifier
svc = SVC()
svc.fit(x_train, y_train)
y_pred = svc.predict(x_test)

# Model accuracy
confusion_matrix(y_test, y_pred)
print(classification_report(y_test, y_pred))

# Hyperparameter tuning
param_grid = {'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0, 0.01], 'kernel': ['rbf'], 'class_weight': ['balanced']}
grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=2, cv=2)
grid.fit(x_train, y_train)
print(grid.best_estimator_)
grid_predictions = grid.predict(x_test)
confusion_matrix(y_test, grid_predictions)
print(classification_report(y_test, grid_predictions))

# Model with random under sampling
svc_rus = SVC()
svc_rus.fit(x_train_rus, y_train_rus)
y_pred_rus = svc_rus.predict(x_test_rus)

# Model accuracy
confusion_matrix(y_test_rus, y_pred_rus)
print(classification_report(y_test_rus, y_pred_rus))

# Hyperparameter tuning for random under sampling
param_grid_rus = {'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01], 'kernel': ['rbf'], 'class_weight': ['balanced']}
grid_rus = GridSearchCV(SVC(), param_grid_rus, refit=True, verbose=2, cv=2)
grid_rus.fit(x_train_rus, y_train_rus)
print(grid_rus.best_estimator_)
grid_predictions_rus = grid_rus.predict(x_test_rus)
confusion_matrix(y_test_rus, grid_predictions_rus)
print(classification_report(y_test_rus, grid_predictions_rus))

# Model with random over sampling
svc_ros = SVC()
svc_ros.fit(x_train_ros, y_train_ros)
y_pred_ros = svc_ros.predict(x_test_ros)

# Model accuracy
confusion_matrix(y_test_ros, y_pred_ros)
print(classification_report(y_test_ros, y_pred_ros))

# Hyperparameter tuning for random over sampling
param_grid_ros = {'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01], 'kernel': ['rbf'], 'class_weight': ['balanced']}
grid_ros = GridSearchCV(SVC(), param_grid_ros, refit=True, verbose=2, cv=2)
grid_ros.fit(x_train_ros, y_train_ros)
print(grid_ros.best_estimator_)
grid_predictions_ros = grid_ros.predict(x_test_ros)
confusion_matrix(y_test_ros, grid_predictions_ros)
print(classification_report(y_test_ros, grid_predictions_ros))

# Print classification reports
print("Classification report for original data:")
print(classification_report(y_test, y_pred))
print("Classification report for random under-sampled data:")
print(classification_report(y_test_rus, y_pred_rus))
print("Classification report for random over-sampled data:")
print(classification_report(y_test_ros, y_pred_ros))
print("Classification report for random under-sampled data after hyperparameter tuning:")
print(classification_report(y_test_rus, grid_predictions_rus))
print("Classification report for random over-sampled data after hyperparameter tuning:")
print(classification_report(y_test_ros, grid_predictions_ros))
